{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from scipy.cluster.vq import *\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "train_clf_sift= joblib.load(\"svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(txt, X, Y):\n",
    "    fp = open(txt, 'r')\n",
    "    for line in iter(fp):\n",
    "        X_tmp,Y_tmp = [i for i in line.split()]\n",
    "        X.append(X_tmp)\n",
    "        Y.append(Y_tmp)\n",
    "    fp.close\n",
    "    return\n",
    "\n",
    "def sift(des_list, X, Y):\n",
    "    a = 0\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    print(\"Calculating all the descriptors and keypoints...\")\n",
    "    for i in X:\n",
    "        a += 1\n",
    "        print(\"Calculating for image \"+str(a)+\"/\"+str(len(X)), end=\"\\r\")\n",
    "        im  = cv2.imread(i)\n",
    "        im = cv2.resize(im, (64, 64))\n",
    "        gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) \n",
    "        kp, des = sift.detectAndCompute(gray,None)\n",
    "        des_list.append((i, kp, des))\n",
    "    a2=0\n",
    "    \n",
    "    for j, j1, j2 in des_list[1:]:\n",
    "        if j2 is None:\n",
    "            a2 = a2+1\n",
    "            del des_list[a2]\n",
    "            del X[a2]\n",
    "            del Y[a2]\n",
    "            a2 = a2-1\n",
    "        else:\n",
    "            a2 = a2+1\n",
    "            print(\"Calculating for image \"+str(a2)+\"/\"+str(len(des_list)), end=\"\\r\")\n",
    "    return\n",
    "\n",
    "def knn_sift(des_list):\n",
    "    a1 = 0\n",
    "    print(\"Stacking all the descriptors in a numpy array...\")\n",
    "    descriptors = des_list[0][2]\n",
    "    for image_path, keypoints, descriptor in des_list[1:]:\n",
    "        a1=a1+1\n",
    "        print(\"Calculating for image [\"+ str(a1)+\"/\"+str(len(des_list)) +\"]\", end=\"\\r\")\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "        \n",
    "    k = 128\n",
    "    voc, variance = kmeans(descriptors, k, 1)\n",
    "    print(\"Done doing K-means\")\n",
    "    \n",
    "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
    "    for i in range(len(des_list)):\n",
    "        print(\"Calculating distance for image \"+str(i)+\"...\", end=\"\\r\")\n",
    "        words, distance = vq(des_list[i][2],voc)\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "            \n",
    "    nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "    idf = np.array(np.log((1.0*len(des_list) + 1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "    scaled_im_features = im_features * idf\n",
    "            \n",
    "    stdSlr = StandardScaler().fit(scaled_im_features)\n",
    "    scaled_im_features = stdSlr.transform(scaled_im_features)\n",
    "    \n",
    "    return scaled_im_features\n",
    "\n",
    "def linesvc(scaled_im_features, Y):\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X=scaled_im_features, y=Y)\n",
    "    return clf\n",
    "\n",
    "def svc_predict(clf, test):\n",
    "    y_predict = clf.predict(test)\n",
    "    return y_predict\n",
    "\n",
    "def svc_save(clf):\n",
    "    joblib.dump((clf),\"svc.pkl\")\n",
    "    return\n",
    "\n",
    "def LBP(des_list, X, Y):\n",
    "    radius = 1\n",
    "    n_points = 8\n",
    "    a = 0\n",
    "    print(\"Calculating all the descriptors and keypoints...\")\n",
    "    for i in X:\n",
    "        a += 1\n",
    "        print(\"Calculating for image \"+str(a)+\"/\"+str(len(X)), end=\"\\r\")\n",
    "        im  = cv2.imread(i)\n",
    "        im = cv2.resize(im, (64, 64))\n",
    "        gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) \n",
    "        lbp = local_binary_pattern(gray, n_points, radius)\n",
    "        des_list.append(lbp)       \n",
    "    a2=0\n",
    "    \n",
    "    for j in des_list:\n",
    "        if j is None:\n",
    "            a2 = a2+1\n",
    "            del des_list[a2]\n",
    "            del X[a2]\n",
    "            del Y[a2]\n",
    "            a2 = a2-1\n",
    "        else:\n",
    "            a2 = a2+1\n",
    "            print(\"Calculating for image \"+str(a2)+\"/\"+str(len(des_list)), end=\"\\r\")\n",
    "    return\n",
    "\n",
    "def knn_lbp(des_list):\n",
    "    a1 = 0\n",
    "    print(\"Stacking all the descriptors in a numpy array...\")\n",
    "    descriptors = des_list[0]\n",
    "    for descriptor in des_list[1:]:\n",
    "        a1=a1+1\n",
    "        print(\"Calculating for image [\"+ str(a1)+\"/\"+str(len(des_list)) +\"]\", end=\"\\r\")\n",
    "        descriptors = np.vstack((descriptors, descriptor))\n",
    "        \n",
    "    k = 128\n",
    "    voc, variance = kmeans(descriptors, k, 1)\n",
    "    print(\"Done doing K-means\")\n",
    "    \n",
    "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
    "    for i in range(len(des_list)):\n",
    "        print(\"Calculating distance for image \"+str(i)+\"...\", end=\"\\r\")\n",
    "        words, distance = vq(des_list[i],voc)\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "            \n",
    "    nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "    idf = np.array(np.log((1.0*len(des_list) + 1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "    scaled_im_features = im_features * idf\n",
    "            \n",
    "    stdSlr = StandardScaler().fit(scaled_im_features)\n",
    "    scaled_im_features = stdSlr.transform(scaled_im_features)\n",
    "    \n",
    "    return scaled_im_features\n",
    "\n",
    "def svc_save_lbp(clf):\n",
    "    joblib.dump((clf),\"svc_lbp.pkl\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all the descriptors and keypoints...\n",
      "Calculating all the descriptors and keypoints...\n",
      "Calculating all the descriptors and keypoints...\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [63316/63317]\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [448/449]\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [449/450]\n",
      "Calculating distance for image 449...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmpss\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_sift = []\n",
    "Y_train_sift = []\n",
    "X_test_sift = []\n",
    "Y_test_sift = []\n",
    "X_val_sift = []\n",
    "Y_val_sift = []\n",
    "des_train_sift = []\n",
    "des_test_sift = []        \n",
    "des_val_sift = []\n",
    "read('train.txt', X_train_sift, Y_train_sift)\n",
    "read('test.txt', X_test_sift, Y_test_sift)\n",
    "read('val.txt', X_val_sift, Y_val_sift)\n",
    "sift(des_train_sift, X_train_sift, Y_train_sift)\n",
    "sift(des_test_sift, X_test_sift, Y_test_sift)\n",
    "sift(des_val_sift, X_val_sift, Y_val_sift)\n",
    "scaled_train_sift = knn_sift(des_train_sift)\n",
    "scaled_test_sift = knn_sift(des_test_sift)\n",
    "scaled_val_sift = knn_sift(des_val_sift)\n",
    "train_clf_sift=linesvc(scaled_train_sift, Y_train_sift)\n",
    "svc_save(train_clf_sift)\n",
    "test_predict_sift = svc_predict(train_clf_sift, scaled_test_sift)\n",
    "val_predict_sift = svc_predict(train_clf_sift, scaled_val_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all the descriptors and keypoints...\n",
      "Calculating all the descriptors and keypoints...\n",
      "Calculating all the descriptors and keypoints...\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [63324/63325]\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [449/450]\n",
      "Stacking all the descriptors in a numpy array...\n",
      "Done doing K-meansage [449/450]\n",
      "Calculating distance for image 449...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmpss\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_lbp = []\n",
    "Y_train_lbp = []\n",
    "X_test_lbp = []\n",
    "Y_test_lbp = []\n",
    "X_val_lbp = []\n",
    "Y_val_lbp = []\n",
    "des_train_lbp = []\n",
    "des_test_lbp = []        \n",
    "des_val_lbp = []\n",
    "read('train.txt', X_train_lbp, Y_train_lbp)\n",
    "read('test.txt', X_test_lbp, Y_test_lbp)\n",
    "read('val.txt', X_val_lbp, Y_val_lbp)\n",
    "LBP(des_train_lbp, X_train_lbp, Y_train_lbp)\n",
    "LBP(des_test_lbp, X_test_lbp, Y_test_lbp)\n",
    "LBP(des_val_lbp, X_val_lbp, Y_val_lbp)\n",
    "scaled_train_lbp = knn_lbp(des_train_lbp)\n",
    "scaled_test_lbp = knn_lbp(des_test_lbp)\n",
    "scaled_val_lbp = knn_lbp(des_val_lbp)\n",
    "train_clf_lbp=linesvc(scaled_train_lbp, Y_train_lbp)\n",
    "svc_save_lbp(train_clf_lbp)\n",
    "test_predict_lbp = svc_predict(train_clf_lbp, scaled_test_lbp)\n",
    "val_predict_lbp = svc_predict(train_clf_lbp, scaled_val_lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc準確度\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.028888888888888888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sift精確度\")\n",
    "metrics.precision_score(val_predict_sift, Y_val_sift, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift準確度\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017817371937639197"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sift準確度\")\n",
    "accuracy_score(test_predict_sift, Y_test_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbp精確度\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013333333333333334"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"lbp精確度\")\n",
    "metrics.precision_score(val_predict_lbp, Y_val_lbp, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbp準確度\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022222222222222223"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"lbp準確度\")\n",
    "accuracy_score(test_predict_lbp, Y_test_lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
